{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434a978-6aca-40d1-8ece-31d3e46b65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 데이터셋 경로 설정\n",
    "dataset_dir = \"/home/yycho/deepMUC/202230727_Image/HILOW\"\n",
    "dataset_dir = Path(dataset_dir)\n",
    "\n",
    "# 이미지 파일 경로 수집\n",
    "filepaths = list(dataset_dir.glob(r'*/*.jpg'))\n",
    "print(f\"총 {len(filepaths)}개의 이미지 파일을 찾았습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72444e-3943-43ef-bab9-86173e55dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 생성\n",
    "def create_image_df(filepaths):\n",
    "    labels = [filepath.parent.name for filepath in filepaths]\n",
    "    df = pd.DataFrame({'Filepath': filepaths, 'Label': labels})\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # 데이터프레임 셔플\n",
    "    return df\n",
    "\n",
    "image_df = create_image_df(filepaths)\n",
    "print(image_df.head())\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder_img = LabelEncoder()\n",
    "image_df['Encoded_Label'] = label_encoder_img.fit_transform(image_df['Label'])  # 'High' => 0, 'Low' => 1\n",
    "\n",
    "# 원-핫 인코딩\n",
    "image_df['Categorical_Label'] = list(to_categorical(image_df['Encoded_Label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebc5d7-55d8-4035-b603-98a6b50093ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def proc_img(filepath):\n",
    "    \"\"\"\n",
    "   \t\t이미지데이터의 경로와 label데이터로 데이터프레임 만들기 \n",
    "    \"\"\"\n",
    "\n",
    "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
    "              for i in range(len(filepath))]\n",
    "\n",
    "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # 경로와 라벨 concatenate\n",
    "    df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "    # index 재설정\n",
    "    df = df.sample(frac=1,random_state=0).reset_index(drop = True)\n",
    "    \n",
    "    return df\n",
    "df = proc_img(filepaths)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280aa98c-e59c-45a9-bf42-874ba95d6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_image_paths = image_df['Filepath'].astype(str).values\n",
    "y_image = np.stack(image_df['Categorical_Label'].values)\n",
    "\n",
    "# 학습용과 테스트용 데이터 분할\n",
    "X_image_train_paths, X_image_test_paths, y_image_train, y_image_test = train_test_split(\n",
    "    X_image_paths, y_image, test_size=0.2, random_state=42, stratify=y_image\n",
    ")\n",
    "\n",
    "print(f\"학습용 이미지 데이터 수: {len(X_image_train_paths)}\")\n",
    "print(f\"테스트용 이미지 데이터 수: {len(X_image_test_paths)}\")\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 증강 및 전처리를 위한 ImageDataGenerator 설정\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.densenet.preprocess_input,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.densenet.preprocess_input\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d352e2-a56d-40bb-a424-4f6bbe0e840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제너레이터 함수 정의\n",
    "def create_generator(filepaths, labels, datagen, batch_size):\n",
    "    num_samples = len(filepaths)\n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_filepaths = filepaths[batch_indices]\n",
    "            batch_labels = labels[batch_indices]\n",
    "            batch_images = []\n",
    "            for filepath in batch_filepaths:\n",
    "                img = tf.keras.preprocessing.image.load_img(filepath, target_size=(299, 299))\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                batch_images.append(img_array)\n",
    "            batch_images = np.array(batch_images)\n",
    "            batch_images = datagen.standardize(batch_images)\n",
    "            yield batch_images, batch_labels\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# 모델 구성\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)  # 클래스 수에 따라 조정\n",
    "image_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 모델 컴파일\n",
    "image_model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 콜백 설정\n",
    "checkpoint = ModelCheckpoint('image_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.1, min_lr=1e-6, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# 배치 크기와 스텝 계산\n",
    "batch_size = 32\n",
    "train_steps = len(X_image_train_paths) // batch_size\n",
    "test_steps = len(X_image_test_paths) // batch_size\n",
    "\n",
    "# 제너레이터 생성\n",
    "train_generator = create_generator(X_image_train_paths, y_image_train, train_datagen, batch_size)\n",
    "test_generator = create_generator(X_image_test_paths, y_image_test, test_datagen, batch_size)\n",
    "\n",
    "# 모델 학습\n",
    "history_img = image_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_steps,\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint, reduce_lr, early_stop]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321614a-395d-436c-bbe1-79f9528797db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 최적의 모델 로드\n",
    "best_image_model = tf.keras.models.load_model('na_HI_LOW.h5')\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_loss, test_accuracy = best_image_model.evaluate(test_generator, steps=test_steps)\n",
    "print(f\"테스트 손실: {test_loss}\")\n",
    "print(f\"테스트 정확도: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
